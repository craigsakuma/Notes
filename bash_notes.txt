***BASH NOTES

- ls -l #list with details
- ls -ltr #list with details in order of last saved
- ls -a #list with hidden files
- ls -la #list with details and hidden files
- cd ../.. (goes up two directories)
- ./ for current directory
- cp filename ../../dev (saves file in dev folder that's two directories below current directory
- cp -r <target> <destination> copies directory and includes subdirectories and files
- pbcopy < [filename] # command to copy file to clipboard
- mv can be used to rename files
- tab will autocomplete
- rmdir ??? to remove directory with file names

chmod ### <file>
0 == --- == no access
1 == --x == execute
2 == -w- == write
3 == -wx == write / execute
4 == r-- == read
5 == r-x == read / execute
6 == rw- == read / write
7 == rwx == read / write / execute

pip
- pip freeze #lists all packages installed via pip
- pip install --upgrade [package name] #upgrades existing package
- check version of pip (i.e., might be pip2 install)

homebrew
- brew update
- brew upgrade
- brew doctor

.bash_profile
- located in /users/Craig_Sakuma/
- set path.... is used to order paths when searching for files

copy files instead of SCP
- rsync -avP feste.json ec2:  #copy feste.json from local drive to ec2 (requires set up of ec2 in .ssh config file)
- rsync -avP [target file path] [userid]@[awsnode]:[file path]
- rsync -avP .ssh/awsSec.sec dsack@ec2-23-22-209-93.compute-1.amazonaws.com:.ssh/

check path
- echo $PYTHONPATH

setting up ssh
- config* file in .ssh folder to set ssh shortcuts so you can just type 'ssh ec2' to log in
"""
Host ec2
    HostName ec2-23-22-209-93.compute-1.amazonaws.com
    User dsack 
    IdentityFile <path:file for ssh_key>

Host spark
    HostName ec2-54-242-6-62.compute-1.amazonaws.com
    User root
"""
- add github ssh key in .ssh folder and follow instructions at github (register key, change url)


Tool for S3 - s3cmd
- command line tool for s3
- allows you to check s3 while in ec2
- example: s3cmd ls  
- example: s3cmd put [filename] s3://test-euclid-dstrauss/  # takes file on ec2 and moves it to s3 in the test-euclid-dstrauss bucket
- s3cmd del -r s3://BUCKET/OBJECT # delete file from bucket recursive


SCREEN COMMAND
- screen # creates remote screen that will continue to run (avoids broken connections)
- cntrl-a, d # leave screen without closing session
- screen -r # re-opens session
- use exit to close screen
- link for more info - https://kb.iu.edu/data/acuy.html


